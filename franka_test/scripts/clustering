#!/usr/bin/env python

########## global imports ##########
import numpy as np
import matplotlib.pyplot as plt
import os
import yaml

import seaborn as sns
from argparse import Namespace

import rospy
from std_msgs.msg import Empty
from franka_test.msg import Distribution

########## local imports ##########
import sys, os
from load_config import get_config
from dist_modules.clustering import relabel, plot_gmm_results, process_clusters
from plotting.plotting_matplotlib import set_mpl_format

## change default figure params
set_mpl_format()

class Clustering(object):
    def __init__(self):
        rospy.init_node('clustering')
        rospy.Subscriber('/update_processes',Empty,self.update_process_callback)

        test_path = rospy.get_param('test_path', '')

        if test_path == '':
            # new config so load from scratch file
            args = get_config(print_output=False)
        else:
            # test config so load from previous training
            base_path = rospy.get_param('base_path', './')
            full_test_path = base_path + '/' + test_path + '/'
            fingerprint_path = rospy.get_param("fingerprint_path", "eval/")
            fp_path = fingerprint_path.split(' ')[0] # just saving in the first place

            args = Namespace()
            with open(full_test_path + "/config.yaml","r") as f:
                params = yaml.load(f, Loader=yaml.FullLoader)
            for k, v in params.items():
                setattr(args, k, v)

            # load exploration / training config modification (if applicable)
            test_config_file = rospy.get_param("test_config_file", "fp_trainer_config.yaml")
            save_name = rospy.get_param('save_name', 'test')

            src_file = base_path+'/config/' + test_config_file
            with open(src_file) as f:
                tmp = yaml.load(f,Loader=yaml.FullLoader)
            for _, param in tmp.items(): # top level is for user readability
                for k, v in param.items():
                    setattr(args, k, v)
            args.dir_path = full_test_path + '/../test_explr_tmp_'+save_name.split('/')[0] + '/' # just saving the first place
            if os.path.exists(args.dir_path) == False:
                os.makedirs(args.dir_path)


        self.plot_states = args.plot_states
        self.plot_idx = args.plot_idx
        self.plot_lims = np.array(args.robot_lim)[self.plot_idx]
        num_samples = 50
        self.plot_grid = np.meshgrid(*[np.linspace(*self.plot_lims, num_samples)]*2)
        self.dist_msg = None
        self.last_clusters = None
        self.cluster_log = []
        self.cluster_names = ['step','error','num_clusters','clusters','stable?']

        # set up figures
        self.fig = None
        self.plot_data = None
        self.done = False
        self.render = args.render_figs
        self.save_figs = args.save_figs
        self.save_path = args.dir_path + 'clusters/'
        if os.path.exists(self.save_path) == False:
            os.makedirs(self.save_path)
        # self.save_figs = False

        ### Setup Ros Env ###
        self.rate = rospy.Rate(10)
        rospy.Subscriber('~distribution',Distribution,self.distribution_callback)
        self.save = rospy.Publisher('/save',Empty,queue_size=1,latch=False)
        rospy.Subscriber('/stop',Empty,self.stop_callback)
 
    def update_process_callback(self,msg):
        import psutil
        p = psutil.Process()
        node_name = rospy.get_name()
        # print(f'***** {node_name} node ***** ',os.environ['OMP_NUM_THREADS'],p.cpu_affinity(),'*****')
        ros_affinity = rospy.get_param('ros_affinity',{})
        if node_name in ros_affinity.keys():
            cores = ros_affinity[node_name]
            p.cpu_affinity(cores)
        # print(f'***** {node_name} node ***** ',os.environ['OMP_NUM_THREADS'],p.cpu_affinity(),'*****')

    def stop_callback(self,msg):
        self.done = True

    def distribution_callback(self,msg):
        self.dist_msg = msg 
    
    def update_clusters(self):
        msg = self.dist_msg
        self.dist_msg = None
        samples = np.array(msg.samples).reshape(msg.samples_layout)
        distribution = np.array(msg.distribution)
        cluster_means = self.find_clusters(msg.explr_step,msg.learning_ind,samples,distribution)
        if self.last_clusters is not None:
            num_clusters = len(cluster_means)
            if num_clusters == len(self.last_clusters):
                error = np.sum(( cluster_means - self.last_clusters)**2)/num_clusters
                stable = error < 0.001
                if stable: # check done condition
                    self.save.publish() # tell model to save a checkpoint
            else: 
                error = 'NA'
                stable = False
            self.cluster_log.append([msg.learning_ind,error,num_clusters,cluster_means,stable])            
        self.last_clusters = cluster_means


    def draw_fig(self,vert=True):
        explr_step,learning_ind,samples,dist,X,Y_labels,cluster_means,cluster_covariances,last_clusters = self.plot_data

        ## build fig
        if self.fig is None:
            if vert:
                self.fig,self.axs = plt.subplots(2,1,figsize=(3,6))
            else:
                self.fig,self.axs = plt.subplots(1,2,figsize=(6,3))
            if self.render:
                plt.show(block=False)
        [ax.cla() for ax in self.axs]
        colors = sns.color_palette("Paired")

        ## draw plots
        num_fingerprints = len(cluster_means)
        plot_gmm_results(X, Y_labels, cluster_means, cluster_covariances, self.axs[0],color_iter=colors,title="New Cluster(s)")
        ax = self.axs[1]
        heatmap = ax.tricontourf(*samples[:,self.plot_idx].T,dist,cmap='gist_heat',levels=10)
        for c in heatmap.collections:
            c.set_edgecolor("face")
            c.set_rasterized(True)
        ax.set_title(f'Cluster Comparison')
        if last_clusters is not None:
            [ax.scatter(*mu,color=color,edgecolor='white',marker='^',s=200,label=f'old | {idx}') for idx,(color,mu) in enumerate(zip(colors,last_clusters))]
        [ax.scatter(*mu,color=color,edgecolor='white',marker='o',s=200,label=f'new | {idx}') for idx,(color,mu) in enumerate(zip(colors,cluster_means[:,:2]))]
        if vert:
            ax.legend(loc='center', bbox_to_anchor=(0.5, 1.25), ncol=2)
        else:
            ax.legend(loc='center left', bbox_to_anchor=(1, 0.9), ncol=2)
        for ax in self.axs:
            ax.set_aspect('equal', 'box')
            ax.set_xlim(self.plot_lims[0])
            ax.set_ylim(self.plot_lims[1])
            ax.xaxis.set_ticks(np.linspace(*self.plot_lims[0],5))
            ax.yaxis.set_ticks(np.linspace(*self.plot_lims[1],5))
            plot_label = [p if p == p.lower() else 'd' + p.lower() + '\dt' for p in self.plot_states]
            ax.set_xlabel(plot_label[0])
            ax.set_ylabel(plot_label[1])
        self.fig.tight_layout()

        if self.render:
            self.fig.canvas.draw_idle()
            self.fig.canvas.flush_events()
            self.fig.canvas.start_event_loop(1)
        self.plot_data = None

        ## save fig
        if self.save_figs:
            self.fig.savefig(self.save_path+f'clusters_explrStep{explr_step:05d}_learningIter{learning_ind:05d}.svg')

    def find_clusters(self,explr_step,learning_ind,samples,dist,sample_method='reweight',cluster_method='shift',num_fingerprints=2):

        ## power
        dist *= dist

        X,Y_labels,cluster_means,cluster_covariances,cov_type,clustering_msg = process_clusters(samples,dist,self.plot_idx,num_fingerprints,sample_method,cluster_method,optimize_samples=False,cluster_by_plot_idx=True)

        ## sort by "x"
        order = np.argsort(cluster_means[:,0])
        cluster_means = cluster_means[order]
        if cluster_covariances is not None:
            cluster_covariances = cluster_covariances[order]
        Y_labels = relabel(Y_labels,order)

        ## plot
        self.plot_data = [explr_step,learning_ind,samples,dist,X,Y_labels,cluster_means,cluster_covariances,self.last_clusters]

        return cluster_means[:,:2] 

if __name__== '__main__':
    clustering = Clustering()
    while not rospy.is_shutdown() and not(clustering.done):
        if clustering.dist_msg is not None: 
            clustering.update_clusters()
        if clustering.plot_data is not None:
            clustering.draw_fig()
        if clustering.fig is not None and clustering.fig.stale:
            clustering.fig.canvas.draw_idle()
        clustering.rate.sleep()

    # save log
    import pandas as pd
    pd.DataFrame(clustering.cluster_log,columns=clustering.cluster_names).to_csv(clustering.save_path + 'cluster_log.csv',index=False)
